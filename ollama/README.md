### Installation
1) Bring up ollama container
   ```commandline
    cd ollama
    docker-compose up -d
    ```
2) Pull all the required LLM models in ollama: llama3, nomic-embed-text
3) Run the main.py script to start the chat
    ```commandline
    python main.py
    ```

